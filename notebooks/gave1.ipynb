{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87e509e9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-28T19:43:15.196533Z",
     "iopub.status.busy": "2025-11-28T19:43:15.196280Z",
     "iopub.status.idle": "2025-11-28T19:43:52.034544Z",
     "shell.execute_reply": "2025-11-28T19:43:52.033635Z"
    },
    "papermill": {
     "duration": 36.844333,
     "end_time": "2025-11-28T19:43:52.036026",
     "exception": false,
     "start_time": "2025-11-28T19:43:15.191693",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m439.5/439.5 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\r\n",
      "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\r\n",
      "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\r\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m16.8/16.8 MB\u001b[0m \u001b[31m90.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Building wheel for insightface (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "bigframes 2.12.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\r\n",
      "mkl-umath 0.1.1 requires numpy<1.27.0,>=1.26.4, but you have numpy 2.2.6 which is incompatible.\r\n",
      "mkl-random 1.2.4 requires numpy<1.27.0,>=1.26.4, but you have numpy 2.2.6 which is incompatible.\r\n",
      "mkl-fft 1.3.8 requires numpy<1.27.0,>=1.26.4, but you have numpy 2.2.6 which is incompatible.\r\n",
      "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.2.6 which is incompatible.\r\n",
      "datasets 4.4.1 requires pyarrow>=21.0.0, but you have pyarrow 19.0.1 which is incompatible.\r\n",
      "ydata-profiling 4.17.0 requires numpy<2.2,>=1.16.0, but you have numpy 2.2.6 which is incompatible.\r\n",
      "google-colab 1.0.0 requires notebook==6.5.7, but you have notebook 6.5.4 which is incompatible.\r\n",
      "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.2.3 which is incompatible.\r\n",
      "google-colab 1.0.0 requires requests==2.32.3, but you have requests 2.32.5 which is incompatible.\r\n",
      "google-colab 1.0.0 requires tornado==6.4.2, but you have tornado 6.5.2 which is incompatible.\r\n",
      "dopamine-rl 4.1.2 requires gymnasium>=1.0.0, but you have gymnasium 0.29.0 which is incompatible.\r\n",
      "bigframes 2.12.0 requires rich<14,>=12.4.4, but you have rich 14.2.0 which is incompatible.\r\n",
      "gradio 5.38.1 requires pydantic<2.12,>=2.0, but you have pydantic 2.12.4 which is incompatible.\r\n",
      "imbalanced-learn 0.13.0 requires scikit-learn<2,>=1.3.2, but you have scikit-learn 1.2.2 which is incompatible.\r\n",
      "plotnine 0.14.5 requires matplotlib>=3.8.0, but you have matplotlib 3.7.2 which is incompatible.\r\n",
      "tensorflow 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 2.2.6 which is incompatible.\r\n",
      "tensorflow 2.18.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3, but you have protobuf 6.33.0 which is incompatible.\r\n",
      "pylibcugraph-cu12 25.6.0 requires pylibraft-cu12==25.6.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\r\n",
      "pylibcugraph-cu12 25.6.0 requires rmm-cu12==25.6.*, but you have rmm-cu12 25.2.0 which is incompatible.\r\n",
      "umap-learn 0.5.9.post2 requires scikit-learn>=1.6, but you have scikit-learn 1.2.2 which is incompatible.\r\n",
      "mlxtend 0.23.4 requires scikit-learn>=1.3.1, but you have scikit-learn 1.2.2 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m300.5/300.5 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!pip install insightface --upgrade --quiet\n",
    "!pip install onnxruntime-gpu --upgrade --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b9c0917",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-28T19:43:52.049766Z",
     "iopub.status.busy": "2025-11-28T19:43:52.049530Z",
     "iopub.status.idle": "2025-11-28T19:43:52.395813Z",
     "shell.execute_reply": "2025-11-28T19:43:52.394929Z"
    },
    "papermill": {
     "duration": 0.354352,
     "end_time": "2025-11-28T19:43:52.397121",
     "exception": false,
     "start_time": "2025-11-28T19:43:52.042769",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Nov 28 19:43:52 2025       \r\n",
      "+-----------------------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 570.172.08             Driver Version: 570.172.08     CUDA Version: 12.8     |\r\n",
      "|-----------------------------------------+------------------------+----------------------+\r\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                                         |                        |               MIG M. |\r\n",
      "|=========================================+========================+======================|\r\n",
      "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\r\n",
      "| N/A   37C    P8              9W /   70W |       0MiB /  15360MiB |      0%      Default |\r\n",
      "|                                         |                        |                  N/A |\r\n",
      "+-----------------------------------------+------------------------+----------------------+\r\n",
      "|   1  Tesla T4                       Off |   00000000:00:05.0 Off |                    0 |\r\n",
      "| N/A   38C    P8              9W /   70W |       0MiB /  15360MiB |      0%      Default |\r\n",
      "|                                         |                        |                  N/A |\r\n",
      "+-----------------------------------------+------------------------+----------------------+\r\n",
      "                                                                                         \r\n",
      "+-----------------------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                              |\r\n",
      "|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\r\n",
      "|        ID   ID                                                               Usage      |\r\n",
      "|=========================================================================================|\r\n",
      "|  No running processes found                                                             |\r\n",
      "+-----------------------------------------------------------------------------------------+\r\n",
      "nvcc: NVIDIA (R) Cuda compiler driver\r\n",
      "Copyright (c) 2005-2024 NVIDIA Corporation\r\n",
      "Built on Thu_Jun__6_02:18:23_PDT_2024\r\n",
      "Cuda compilation tools, release 12.5, V12.5.82\r\n",
      "Build cuda_12.5.r12.5/compiler.34385749_0\r\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# VÃ©rifier la version du driver NVIDIA et du GPU\n",
    "!nvidia-smi\n",
    "\n",
    "# VÃ©rifier la version de CUDA installÃ©e\n",
    "!nvcc --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "50052c4c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-28T19:43:52.410770Z",
     "iopub.status.busy": "2025-11-28T19:43:52.410547Z",
     "iopub.status.idle": "2025-11-28T19:43:52.710640Z",
     "shell.execute_reply": "2025-11-28T19:43:52.709766Z"
    },
    "papermill": {
     "duration": 0.308306,
     "end_time": "2025-11-28T19:43:52.711823",
     "exception": false,
     "start_time": "2025-11-28T19:43:52.403517",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#define CUDNN_MAJOR 9\r\n",
      "#define CUDNN_MINOR 2\r\n",
      "#define CUDNN_PATCHLEVEL 1\r\n",
      "--\r\n",
      "#define CUDNN_VERSION (CUDNN_MAJOR * 10000 + CUDNN_MINOR * 100 + CUDNN_PATCHLEVEL)\r\n",
      "\r\n",
      "/* cannot use constexpr here since this is a C-only file */\r\n"
     ]
    }
   ],
   "source": [
    "# VÃ©rifier la version de cuDNN\n",
    "!cat /usr/include/cudnn_version.h | grep CUDNN_MAJOR -A 2\n",
    "!sudo ln -sf /usr/local/cuda/lib64/libcublasLt.so.12 /usr/local/cuda/lib64/libcublasLt.so.11\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "433f38e3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-28T19:43:52.725359Z",
     "iopub.status.busy": "2025-11-28T19:43:52.725126Z",
     "iopub.status.idle": "2025-11-28T19:43:52.842921Z",
     "shell.execute_reply": "2025-11-28T19:43:52.842141Z"
    },
    "papermill": {
     "duration": 0.126268,
     "end_time": "2025-11-28T19:43:52.844405",
     "exception": false,
     "start_time": "2025-11-28T19:43:52.718137",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lrwxrwxrwx 1 root root 39 Nov 28 19:43 \u001b[0m\u001b[01;36m/usr/local/cuda/lib64/libcublasLt.so.11\u001b[0m -> /usr/local/cuda/lib64/libcublasLt.so.12\r\n"
     ]
    }
   ],
   "source": [
    "ls -l /usr/local/cuda/lib64/libcublasLt.so.11\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64f1571d",
   "metadata": {
    "execution": {},
    "papermill": {
     "duration": 1.009831,
     "end_time": "2025-11-28T19:43:53.861638",
     "exception": false,
     "start_time": "2025-11-28T19:43:52.851807",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.kill(os.getpid(), 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "488b0ec9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-28T10:08:30.592815Z",
     "iopub.status.busy": "2025-11-28T10:08:30.592471Z",
     "iopub.status.idle": "2025-11-28T10:09:32.338959Z",
     "shell.execute_reply": "2025-11-28T10:09:32.338158Z",
     "shell.execute_reply.started": "2025-11-28T10:08:30.592774Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install onnxruntime-gpu==1.20.0  # compatible CUDA 12\n",
    "import onnxruntime as ort\n",
    "print(\"Available providers:\", ort.get_available_providers())\n",
    "!pip install insightface onnxruntime-gpu tqdm\n",
    "!pip uninstall -y matplotlib insightface onnxruntime onnxruntime-gpu\n",
    "!pip install matplotlib==3.8.4 insightface onnxruntime-gpu tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7943c1de",
   "metadata": {
    "execution": {
     "execution_failed": "2025-11-28T10:09:32.971Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "os.kill(os.getpid(), 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d46c7069",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-28T10:11:41.112121Z",
     "iopub.status.busy": "2025-11-28T10:11:41.111812Z",
     "iopub.status.idle": "2025-11-28T10:11:44.538944Z",
     "shell.execute_reply": "2025-11-28T10:11:44.538118Z",
     "shell.execute_reply.started": "2025-11-28T10:11:41.112099Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install insightface\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa5df242",
   "metadata": {
    "execution": {
     "execution_failed": "2025-11-28T10:11:47.993Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.kill(os.getpid(), 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf1a64c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-28T10:11:53.213435Z",
     "iopub.status.busy": "2025-11-28T10:11:53.212723Z",
     "iopub.status.idle": "2025-11-28T12:08:21.563115Z",
     "shell.execute_reply": "2025-11-28T12:08:21.562119Z",
     "shell.execute_reply.started": "2025-11-28T10:11:53.213409Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# ğŸ”¹ Initialisation InsightFace\n",
    "# -------------------------------\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import shutil\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from insightface.app import FaceAnalysis\n",
    "\n",
    "# -------------------------------\n",
    "# âš™ï¸ ParamÃ¨tres\n",
    "# -------------------------------\n",
    "dataset_root = \"/kaggle/input/cacd-filtered-dataset/cacd_split/cacd_split\"\n",
    "output_root = \"/kaggle/working/cacd_cleaned_dataset_fast\"\n",
    "csv_file = os.path.join(output_root, \"cacd_cleaned_dataset_fast.csv\")\n",
    "\n",
    "# Tranches d'Ã¢ge pour StarGAN\n",
    "age_groups = {\n",
    "    \"trainA\": (0, 24),    # jeunes <25\n",
    "    \"trainB\": (25, 49),   # adultes 25-49\n",
    "    \"trainC\": (50, 150)   # vieux â‰¥50\n",
    "}\n",
    "\n",
    "os.makedirs(output_root, exist_ok=True)\n",
    "for group in age_groups.keys():\n",
    "    os.makedirs(os.path.join(output_root, group), exist_ok=True)\n",
    "\n",
    "\n",
    "print(\"ğŸš€ Chargement du modÃ¨le InsightFace Age...\")\n",
    "app = FaceAnalysis(providers=['CUDAExecutionProvider'])  # GPU\n",
    "app.prepare(ctx_id=0)  # ctx_id=0 pour GPU 0\n",
    "print(\"âœ… ModÃ¨le prÃªt !\")\n",
    "\n",
    "# -------------------------------\n",
    "# ğŸ”¹ Fonction de traitement d'une image\n",
    "# -------------------------------\n",
    "def process_image(star_folder, img_file):\n",
    "    folder_path = os.path.join(dataset_root, star_folder)\n",
    "    img_path = os.path.join(folder_path, img_file)\n",
    "\n",
    "    img = cv2.imread(img_path)\n",
    "    if img is None:\n",
    "        return None\n",
    "\n",
    "    faces = app.get(img)\n",
    "    if not faces:\n",
    "        return None  # pas de visage dÃ©tectÃ©\n",
    "\n",
    "    age_pred = int(faces[0].age)\n",
    "\n",
    "    # DÃ©terminer tranche d'Ã¢ge\n",
    "    for group, (min_age, max_age) in age_groups.items():\n",
    "        if min_age <= age_pred <= max_age:\n",
    "            group_folder = os.path.join(output_root, group, star_folder)\n",
    "            os.makedirs(group_folder, exist_ok=True)\n",
    "            new_name = f\"{age_pred}_{star_folder}_{img_file.split('_')[-1]}\"\n",
    "            new_path = os.path.join(group_folder, new_name)\n",
    "            shutil.copy(img_path, new_path)\n",
    "            return {\n",
    "                \"star\": star_folder,\n",
    "                \"original_image\": img_file,\n",
    "                \"predicted_age\": age_pred,\n",
    "                \"new_name\": new_name,\n",
    "                \"age_group\": group\n",
    "            }\n",
    "    return None\n",
    "\n",
    "# -------------------------------\n",
    "# ğŸ”¹ PrÃ©parer toutes les images\n",
    "# -------------------------------\n",
    "all_images = []\n",
    "for star_folder in os.listdir(dataset_root):\n",
    "    folder_path = os.path.join(dataset_root, star_folder)\n",
    "    if not os.path.isdir(folder_path):\n",
    "        continue\n",
    "    for img_file in os.listdir(folder_path):\n",
    "        if img_file.lower().endswith((\".jpg\", \".jpeg\", \".png\")):\n",
    "            all_images.append((star_folder, img_file))\n",
    "\n",
    "print(f\"ğŸ“Š Total images Ã  traiter : {len(all_images)}\")\n",
    "\n",
    "\n",
    "\n",
    "# -------------------------------\n",
    "# ğŸ”¹ Traitement sÃ©quentiel (GPU)\n",
    "# -------------------------------\n",
    "results = []\n",
    "for star_folder, img_file in tqdm(all_images, total=len(all_images)):\n",
    "    r = process_image(star_folder, img_file)\n",
    "    if r is not None:\n",
    "        results.append(r)\n",
    "\n",
    "# -------------------------------\n",
    "# ğŸ”¹ GÃ©nÃ©ration du CSV\n",
    "# -------------------------------\n",
    "df = pd.DataFrame(results)\n",
    "df.to_csv(csv_file, index=False)\n",
    "print(f\"âœ… Dataset nettoyÃ© et CSV crÃ©Ã© : {csv_file}\")\n",
    "\n",
    "# -------------------------------\n",
    "# ğŸ”¹ Stats rapides\n",
    "# -------------------------------\n",
    "print(\"\\nğŸ“Š Stats par tranche d'Ã¢ge :\")\n",
    "for group in age_groups.keys():\n",
    "    count = len(df[df['age_group'] == group])\n",
    "    print(f\"{group}: {count} images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fca38779",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-28T12:08:21.564874Z",
     "iopub.status.busy": "2025-11-28T12:08:21.564613Z",
     "iopub.status.idle": "2025-11-28T12:08:39.952295Z",
     "shell.execute_reply": "2025-11-28T12:08:39.951625Z",
     "shell.execute_reply.started": "2025-11-28T12:08:21.564854Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# ==============================================\n",
    "# ğŸ”¹ Filtrer les stars prÃ©sentes dans les 3 tranches d'Ã¢ge\n",
    "# ==============================================\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "\n",
    "# -------------------------------\n",
    "# âš™ï¸ ParamÃ¨tres\n",
    "# -------------------------------\n",
    "input_root = \"/kaggle/working/cacd_cleaned_dataset_fast\"\n",
    "output_root = \"/kaggle/working/cacd_complete_stars_dataset\"\n",
    "input_csv = os.path.join(input_root, \"cacd_cleaned_dataset_fast.csv\")\n",
    "output_csv = os.path.join(output_root, \"cacd_complete_stars_dataset.csv\")\n",
    "\n",
    "age_groups = [\"trainA\", \"trainB\", \"trainC\"]\n",
    "\n",
    "os.makedirs(output_root, exist_ok=True)\n",
    "for group in age_groups:\n",
    "    os.makedirs(os.path.join(output_root, group), exist_ok=True)\n",
    "\n",
    "# -------------------------------\n",
    "# ğŸ”¹ Charger le CSV existant\n",
    "# -------------------------------\n",
    "df = pd.read_csv(input_csv)\n",
    "\n",
    "# -------------------------------\n",
    "# ğŸ”¹ Identifier les stars complÃ¨tes\n",
    "# -------------------------------\n",
    "stars_complete = []\n",
    "\n",
    "for star, group_df in df.groupby('star'):\n",
    "    star_groups = set(group_df['age_group'].unique())\n",
    "    if all(g in star_groups for g in age_groups):\n",
    "        stars_complete.append(star)\n",
    "\n",
    "print(f\"â­ Nombre de stars avec images dans les 3 tranches : {len(stars_complete)}\")\n",
    "\n",
    "# -------------------------------\n",
    "# ğŸ”¹ Filtrer le DataFrame\n",
    "# -------------------------------\n",
    "df_filtered = df[df['star'].isin(stars_complete)].copy()\n",
    "\n",
    "# -------------------------------\n",
    "# ğŸ”¹ Copier les images dans le nouveau dossier\n",
    "# -------------------------------\n",
    "for _, row in tqdm(df_filtered.iterrows(), total=len(df_filtered), desc=\"Copie images\"):\n",
    "    src_path = os.path.join(input_root, row['age_group'], row['star'], row['new_name'])\n",
    "    dest_folder = os.path.join(output_root, row['age_group'], row['star'])\n",
    "    os.makedirs(dest_folder, exist_ok=True)\n",
    "    dest_path = os.path.join(dest_folder, row['new_name'])\n",
    "    if not os.path.exists(dest_path):\n",
    "        shutil.copy(src_path, dest_path)\n",
    "\n",
    "# -------------------------------\n",
    "# ğŸ”¹ Enregistrer le CSV final\n",
    "# -------------------------------\n",
    "df_filtered.to_csv(output_csv, index=False)\n",
    "print(f\"âœ… CSV des stars complÃ¨tes crÃ©Ã© : {output_csv}\")\n",
    "\n",
    "# -------------------------------\n",
    "# ğŸ”¹ Stats rapides\n",
    "# -------------------------------\n",
    "print(\"\\nğŸ“Š Stats par tranche d'Ã¢ge pour stars complÃ¨tes :\")\n",
    "for group in age_groups:\n",
    "    count = len(df_filtered[df_filtered['age_group'] == group])\n",
    "    print(f\"{group}: {count} images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b331e1dc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-28T12:08:39.953800Z",
     "iopub.status.busy": "2025-11-28T12:08:39.953513Z",
     "iopub.status.idle": "2025-11-28T12:08:44.474897Z",
     "shell.execute_reply": "2025-11-28T12:08:44.473990Z",
     "shell.execute_reply.started": "2025-11-28T12:08:39.953771Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "root = \"/kaggle/working/cacd_complete_stars_dataset\"\n",
    "splits = ['trainA','trainB','trainC']\n",
    "\n",
    "corrupted = []\n",
    "\n",
    "for sp in splits:\n",
    "    sp_path = os.path.join(root, sp)\n",
    "    if not os.path.isdir(sp_path):\n",
    "        continue\n",
    "    for sub in os.listdir(sp_path):\n",
    "        sub_path = os.path.join(sp_path, sub)\n",
    "        if not os.path.isdir(sub_path):\n",
    "            continue\n",
    "        for f in os.listdir(sub_path):\n",
    "            f_path = os.path.join(sub_path, f)\n",
    "            try:\n",
    "                img = Image.open(f_path)\n",
    "                img.verify()  # VÃ©rifie si l'image est correcte\n",
    "            except:\n",
    "                corrupted.append(f_path)\n",
    "\n",
    "print(f\"Images corrompues trouvÃ©es: {len(corrupted)}\")\n",
    "for f in corrupted:\n",
    "    os.remove(f)\n",
    "    print(f\"SupprimÃ©e: {f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa253ce9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-28T12:08:44.476776Z",
     "iopub.status.busy": "2025-11-28T12:08:44.476415Z",
     "iopub.status.idle": "2025-11-28T12:08:44.482267Z",
     "shell.execute_reply": "2025-11-28T12:08:44.481514Z",
     "shell.execute_reply.started": "2025-11-28T12:08:44.476755Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "samples_dir = \"/kaggle/working/outputs/samples\"\n",
    "\n",
    "if os.path.exists(samples_dir):\n",
    "    # Supprime tout le contenu du dossier samples\n",
    "    for f in os.listdir(samples_dir):\n",
    "        f_path = os.path.join(samples_dir, f)\n",
    "        if os.path.isdir(f_path):\n",
    "            shutil.rmtree(f_path)\n",
    "        else:\n",
    "            os.remove(f_path)\n",
    "    print(f\"âœ… Tout le contenu de {samples_dir} a Ã©tÃ© supprimÃ©\")\n",
    "else:\n",
    "    print(f\"âš ï¸ Le dossier {samples_dir} n'existe pas\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e302c228",
   "metadata": {
    "execution": {
     "execution_failed": "2025-11-28T10:07:50.957Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!rm -f /kaggle/working/starganv2_final_ok/samples/*.jpg\n",
    "print(\"Dossier samples nettoyÃ© â†’ prÃªt pour de nouvelles stars !\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09eeee52",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-28T12:20:55.023987Z",
     "iopub.status.busy": "2025-11-28T12:20:55.023239Z",
     "iopub.status.idle": "2025-11-28T19:36:38.481380Z",
     "shell.execute_reply": "2025-11-28T19:36:38.480386Z",
     "shell.execute_reply.started": "2025-11-28T12:20:55.023960Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# STAR GAN V2 - Version OPTIMISÃ‰E avec transformations d'Ã¢ge visibles\n",
    "import os, random, glob\n",
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "from PIL import Image, ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import save_image\n",
    "from torch.amp import autocast, GradScaler\n",
    "\n",
    "# ====================== CONFIG OPTIMISÃ‰E ======================\n",
    "CFG = {\n",
    "    \"data_root\": \"/kaggle/working/cacd_complete_stars_dataset\",\n",
    "    \"out_dir\": \"/kaggle/working/starganv2_optimized\",\n",
    "    \"iters\": 45000,\n",
    "    \"img_size\": 256,\n",
    "    \"batch_size\": 16,\n",
    "    \"num_workers\": 4,\n",
    "    \"lr\": 2e-4,\n",
    "    \"latent_dim\": 16,\n",
    "    \"style_dim\": 64,\n",
    "    \"n_domains\": 3, # 0=jeune, 1=adulte, 2=Ã¢gÃ©\n",
    "    \"n_res\": 6,\n",
    "    \"lambda_cyc\": 8.0,\n",
    "    \"lambda_cls\": 1.0,\n",
    "    \"lambda_sty\": 1.0,\n",
    "    \"lambda_reg\": 0.0001,\n",
    "    \"lambda_ds\": 1.0,\n",
    "    \"w_hf\": 0.15,\n",
    "    \"sample_every\": 500,\n",
    "    \"save_every\": 5000,\n",
    "    \"seed\": 42\n",
    "}\n",
    "\n",
    "# ====================== SEED ======================\n",
    "def seed_everything(seed=42):\n",
    "    random.seed(seed); np.random.seed(seed)\n",
    "    torch.manual_seed(seed); torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "seed_everything(CFG[\"seed\"])\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "os.makedirs(CFG[\"out_dir\"] + \"/samples\", exist_ok=True)\n",
    "os.makedirs(CFG[\"out_dir\"] + \"/checkpoints\", exist_ok=True)\n",
    "\n",
    "# ====================== DATASET ======================\n",
    "class AgeDataset(Dataset):\n",
    "    def __init__(self, root, img_size=128):\n",
    "        self.samples = []\n",
    "        self.domain_names = [\"trainA\", \"trainB\", \"trainC\"]\n",
    "        for d_idx, folder in enumerate(self.domain_names):\n",
    "            path = os.path.join(root, folder)\n",
    "            if not os.path.isdir(path): continue\n",
    "            for person in os.listdir(path):\n",
    "                person_path = os.path.join(path, person)\n",
    "                if not os.path.isdir(person_path): continue\n",
    "                for file in glob.glob(os.path.join(person_path, \"*.*\")):\n",
    "                    if file.lower().endswith((\".jpg\", \".jpeg\", \".png\", \".bmp\")):\n",
    "                        self.samples.append((file, d_idx))\n",
    "        print(f\"Dataset chargÃ© : {len(self.samples)} images\")\n",
    "        print(f\"RÃ©partition des domaines: {Counter([d for _,d in self.samples])}\")\n",
    "\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.RandomHorizontalFlip(p=0.5),\n",
    "            transforms.Resize((img_size, img_size)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.5]*3, [0.5]*3)\n",
    "        ])\n",
    "\n",
    "    def __len__(self): return len(self.samples)\n",
    "    def __getitem__(self, idx):\n",
    "        path, domain = self.samples[idx]\n",
    "        try:\n",
    "            img = Image.open(path).convert(\"RGB\")\n",
    "        except:\n",
    "            img = Image.new(\"RGB\", (CFG[\"img_size\"], CFG[\"img_size\"]))\n",
    "        return self.transform(img), domain, path\n",
    "\n",
    "# ====================== MODELS ======================\n",
    "def weights_init(m):\n",
    "    if isinstance(m, (nn.Conv2d, nn.ConvTranspose2d, nn.Linear)):\n",
    "        nn.init.normal_(m.weight, 0.0, 0.02)\n",
    "        if hasattr(m, 'bias') and m.bias is not None:\n",
    "            nn.init.constant_(m.bias, 0)\n",
    "\n",
    "class AdaIN(nn.Module):\n",
    "    def __init__(self, channels, style_dim):\n",
    "        super().__init__()\n",
    "        self.norm = nn.InstanceNorm2d(channels, affine=False)\n",
    "        self.style = nn.Linear(style_dim, channels * 2)\n",
    "    def forward(self, x, s):\n",
    "        style = self.style(s)\n",
    "        gamma, beta = style.chunk(2, 1)\n",
    "        gamma = gamma.unsqueeze(-1).unsqueeze(-1)\n",
    "        beta = beta.unsqueeze(-1).unsqueeze(-1)\n",
    "        return gamma * self.norm(x) + beta\n",
    "\n",
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, channels, style_dim):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(channels, channels, 3, 1, 1, bias=False)\n",
    "        self.conv2 = nn.Conv2d(channels, channels, 3, 1, 1, bias=False)\n",
    "        self.adain1 = AdaIN(channels, style_dim)\n",
    "        self.adain2 = AdaIN(channels, style_dim)\n",
    "    def forward(self, x, s):\n",
    "        h = self.conv1(x)\n",
    "        h = self.adain1(h, s)\n",
    "        h = F.relu(h, inplace=True)\n",
    "        h = self.conv2(h)\n",
    "        h = self.adain2(h, s)\n",
    "        return x + h\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, style_dim=64, n_res=6):\n",
    "        super().__init__()\n",
    "        self.enc = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, 7, 1, 3, bias=False), nn.ReLU(True),\n",
    "            nn.Conv2d(64, 128, 4, 2, 1, bias=False), nn.ReLU(True),\n",
    "            nn.Conv2d(128, 256, 4, 2, 1, bias=False), nn.ReLU(True),\n",
    "            nn.Conv2d(256, 512, 4, 2, 1, bias=False), nn.ReLU(True),\n",
    "        )\n",
    "        self.res = nn.ModuleList([ResBlock(512, style_dim) for _ in range(n_res)])\n",
    "        self.dec = nn.Sequential(\n",
    "            nn.ConvTranspose2d(512, 256, 4, 2, 1, bias=False), nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(256, 128, 4, 2, 1, bias=False), nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(128, 64,  4, 2, 1, bias=False), nn.ReLU(True),\n",
    "            nn.Conv2d(64, 3, 7, 1, 3), nn.Tanh()\n",
    "        )\n",
    "    def forward(self, x, s):\n",
    "        h = self.enc(x)\n",
    "        for block in self.res:\n",
    "            h = block(h, s)\n",
    "        return self.dec(h)\n",
    "\n",
    "class MappingNetwork(nn.Module):\n",
    "    def __init__(self, latent_dim=16, style_dim=64, n_domains=3):\n",
    "        super().__init__()\n",
    "        self.n_domains = n_domains\n",
    "        self.shared = nn.Sequential(\n",
    "            nn.Linear(latent_dim, 256), nn.ReLU(True),\n",
    "            nn.Linear(256, 256), nn.ReLU(True),\n",
    "        )\n",
    "        self.branches = nn.ModuleList([\n",
    "            nn.Sequential(\n",
    "                nn.Linear(256, 256), nn.ReLU(True),\n",
    "                nn.Linear(256, style_dim)\n",
    "            ) for _ in range(n_domains)\n",
    "        ])\n",
    "    def forward(self, z, domain):\n",
    "        h = self.shared(z)\n",
    "        styles = [branch(h) for branch in self.branches]\n",
    "        styles = torch.stack(styles, dim=1)\n",
    "        batch_size = z.size(0)\n",
    "        return styles[torch.arange(batch_size), domain]\n",
    "\n",
    "# AJOUT: StyleEncoder pour plus de stabilitÃ©\n",
    "class StyleEncoder(nn.Module):\n",
    "    def __init__(self, style_dim=64, n_domains=3):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, 7, 1, 3), nn.ReLU(True),\n",
    "            nn.Conv2d(64, 128, 4, 2, 1), nn.ReLU(True),\n",
    "            nn.Conv2d(128, 256, 4, 2, 1), nn.ReLU(True),\n",
    "            nn.AdaptiveAvgPool2d(1),\n",
    "        )\n",
    "        self.style = nn.Linear(256, style_dim)\n",
    "        self.classifier = nn.Linear(256, n_domains)\n",
    "       \n",
    "    def forward(self, x):\n",
    "        h = self.net(x).view(x.size(0), -1)\n",
    "        age_hint = torch.sigmoid(self.classifier(h)) * 2 - 1\n",
    "        style = self.style(h) + age_hint.mean(1, keepdim=True) * 0.1\n",
    "        cls_output = self.classifier(h)\n",
    "        return style, cls_output\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, n_domains=3):\n",
    "        super().__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, 4, 2, 1), nn.LeakyReLU(0.2, True),\n",
    "            nn.Conv2d(64, 128, 4, 2, 1), nn.LeakyReLU(0.2, True),\n",
    "            nn.Conv2d(128, 256, 4, 2, 1), nn.LeakyReLU(0.2, True),\n",
    "            nn.Conv2d(256, 512, 4, 2, 1), nn.LeakyReLU(0.2, True),\n",
    "            nn.Conv2d(512, 1024, 4, 1, 0), nn.LeakyReLU(0.2, True),\n",
    "        )\n",
    "        self.src = nn.Conv2d(1024, 1, 3, 1, 1)\n",
    "        self.cls = nn.Conv2d(1024, n_domains, 3, 1, 1)\n",
    "    def forward(self, x):\n",
    "        h = self.main(x)\n",
    "        src = self.src(h).view(x.size(0), -1)\n",
    "        cls = self.cls(h).mean([2,3])\n",
    "        return src, cls\n",
    "\n",
    "# ====================== DATA & MODELS ======================\n",
    "dataset = AgeDataset(CFG[\"data_root\"])\n",
    "counts = Counter([d for _,d in dataset.samples])\n",
    "weights = [1.0 / counts[d] for _,d in dataset.samples]\n",
    "sampler = WeightedRandomSampler(weights, len(weights), replacement=True)\n",
    "loader = DataLoader(dataset, batch_size=CFG[\"batch_size\"], sampler=sampler,\n",
    "                    num_workers=CFG[\"num_workers\"], drop_last=True,\n",
    "                    pin_memory=True, persistent_workers=True)\n",
    "\n",
    "G = Generator(CFG[\"style_dim\"], CFG[\"n_res\"]).to(device)\n",
    "F_map = MappingNetwork(CFG[\"latent_dim\"], CFG[\"style_dim\"], CFG[\"n_domains\"]).to(device)\n",
    "F_style = StyleEncoder(CFG[\"style_dim\"], CFG[\"n_domains\"]).to(device) # AJOUT\n",
    "D = Discriminator(CFG[\"n_domains\"]).to(device)\n",
    "\n",
    "G.apply(weights_init); F_map.apply(weights_init); F_style.apply(weights_init); D.apply(weights_init)\n",
    "\n",
    "opt_g = torch.optim.Adam(list(G.parameters()) + list(F_map.parameters()) + list(F_style.parameters()),\n",
    "                         lr=CFG[\"lr\"], betas=(0.5, 0.999))\n",
    "opt_d = torch.optim.Adam(D.parameters(), lr=CFG[\"lr\"], betas=(0.5, 0.999))\n",
    "scaler_g = GradScaler()\n",
    "scaler_d = GradScaler()\n",
    "\n",
    "# ====================== TRAINING LOOP CORRIGÃ‰ ======================\n",
    "pbar = tqdm(total=CFG[\"iters\"])\n",
    "domain_names = [\"JEUNE\", \"ADULTE\", \"Ã‚GÃ‰\"]\n",
    "\n",
    "for it in range(1, CFG[\"iters\"] + 1):\n",
    "    real, real_domain, _ = next(iter(loader))\n",
    "    real = real.to(device, non_blocking=True)\n",
    "    real_domain = real_domain.to(device, non_blocking=True)\n",
    "    b = real.size(0)\n",
    "\n",
    "    # --- Discriminator ---\n",
    "    opt_d.zero_grad()\n",
    "    with autocast('cuda'):\n",
    "        tgt_domain = torch.randint(0, CFG[\"n_domains\"], (b,), device=device)\n",
    "        z = torch.randn(b, CFG[\"latent_dim\"], device=device)\n",
    "        style = F_map(z, tgt_domain)\n",
    "        fake = G(real, style).detach()\n",
    "\n",
    "        real_src, real_cls = D(real)\n",
    "        fake_src, _ = D(fake)\n",
    "\n",
    "        loss_d_adv = F.softplus(-real_src).mean() + F.softplus(fake_src).mean()\n",
    "        loss_d_cls = F.cross_entropy(real_cls, real_domain)\n",
    "        loss_d = loss_d_adv + CFG[\"lambda_cls\"] * loss_d_cls\n",
    "\n",
    "    scaler_d.scale(loss_d).backward()\n",
    "    scaler_d.step(opt_d)\n",
    "    scaler_d.update()\n",
    "\n",
    "    # --- Generator ---\n",
    "    opt_g.zero_grad()\n",
    "    with autocast('cuda'):\n",
    "        # Adversarial + Classification\n",
    "        tgt_domain = torch.randint(0, CFG[\"n_domains\"], (b,), device=device)\n",
    "        z = torch.randn(b, CFG[\"latent_dim\"], device=device)\n",
    "        style = F_map(z, tgt_domain)\n",
    "        fake = G(real, style)\n",
    "        fake_src, fake_cls = D(fake)\n",
    "\n",
    "        loss_g_adv = -fake_src.mean()\n",
    "        loss_g_cls = F.cross_entropy(fake_cls, tgt_domain)\n",
    "\n",
    "        # Reconstruction cyclique CORRIGÃ‰E\n",
    "        style_orig, _ = F_style(real) # Style depuis l'image originale\n",
    "        rec = G(fake, style_orig)\n",
    "        loss_cyc = F.l1_loss(rec, real)\n",
    "\n",
    "        # Diversity loss CORRIGÃ‰E (encourage la diversitÃ©)\n",
    "        z2 = torch.randn(b, CFG[\"latent_dim\"], device=device)\n",
    "        style2 = F_map(z2, tgt_domain)\n",
    "        fake2 = G(real, style2)\n",
    "        loss_sty = -F.l1_loss(fake, fake2) * CFG[\"lambda_sty\"] # NÃ©gatif = diversitÃ©\n",
    "\n",
    "        # Style regularization\n",
    "        style_reg = F.l1_loss(style, torch.zeros_like(style)) * CFG[\"lambda_reg\"]\n",
    "\n",
    "        # === DIVERSITY SENSITIVE LOSS (force changement cheveux/coupes) ===\n",
    "        z1 = torch.randn(b, CFG[\"latent_dim\"], device=device)\n",
    "        z2 = torch.randn(b, CFG[\"latent_dim\"], device=device)\n",
    "        s1 = F_map(z1, tgt_domain)\n",
    "        s2 = F_map(z2, tgt_domain)\n",
    "        fake1 = G(real, s1)\n",
    "        fake2 = G(real, s2)\n",
    "        loss_ds = torch.mean(torch.abs(fake1 - fake2))\n",
    "        loss_g = (loss_g_adv + CFG[\"lambda_cls\"] * loss_g_cls +\n",
    "                 CFG[\"lambda_cyc\"] * loss_cyc + loss_sty + style_reg +\n",
    "                 CFG[\"lambda_ds\"] * loss_ds)\n",
    "\n",
    "        # === Perceptual High-Frequency Loss (anti-flou puissant et trÃ¨s lÃ©ger) ===\n",
    "        # On pÃ©nalise si l'image gÃ©nÃ©rÃ©e est trop lisse par rapport Ã  la vraie\n",
    "        real_grad_x = torch.abs(real[:, :, :, :-1] - real[:, :, :, 1:])\n",
    "        real_grad_y = torch.abs(real[:, :, :-1, :] - real[:, :, 1:, :])\n",
    "        fake_grad_x = torch.abs(fake[:, :, :, :-1] - fake[:, :, :, 1:])\n",
    "        fake_grad_y = torch.abs(fake[:, :, :-1, :] - fake[:, :, 1:, :])\n",
    "        loss_hf = F.l1_loss(fake_grad_x, real_grad_x) + F.l1_loss(fake_grad_y, real_grad_y)\n",
    "        loss_g += CFG[\"w_hf\"] * loss_hf\n",
    "\n",
    "    scaler_g.scale(loss_g).backward()\n",
    "    scaler_g.step(opt_g)\n",
    "    scaler_g.update()\n",
    "\n",
    "    # --- SAMPLING DIAGNOSTIQUE AMÃ‰LIORÃ‰ ---\n",
    "    if it % CFG[\"sample_every\"] == 0:\n",
    "        G.eval(); F_map.eval(); F_style.eval()\n",
    "        with torch.no_grad():\n",
    "            # Prendre des rÃ©fÃ©rences de CHAQUE domaine\n",
    "            ref_images, ref_domains_list = [], []\n",
    "            for domain in range(CFG[\"n_domains\"]):\n",
    "                domain_mask = (real_domain == domain)\n",
    "                if domain_mask.sum() > 0:\n",
    "                    idx = torch.where(domain_mask)[0][0]\n",
    "                    ref_images.append(real[idx])\n",
    "                    ref_domains_list.append(domain)\n",
    "           \n",
    "            if len(ref_images) >= 2: # Au moins 2 domaines diffÃ©rents\n",
    "                current_ref = torch.stack(ref_images[:min(4, len(ref_images))])\n",
    "                ref_domains = torch.tensor(ref_domains_list[:current_ref.size(0)], device=device)\n",
    "               \n",
    "                outs = [current_ref.cpu()]\n",
    "               \n",
    "                # GÃ©nÃ©rer pour CHAQUE domaine cible\n",
    "                for target_domain in range(CFG[\"n_domains\"]):\n",
    "                    tgt_domains = torch.full((current_ref.size(0),), target_domain, device=device)\n",
    "                    z = torch.randn(current_ref.size(0), CFG[\"latent_dim\"], device=device)\n",
    "                    s = F_map(z, tgt_domains)\n",
    "                    gen = G(current_ref, s)\n",
    "                    outs.append(gen.cpu())\n",
    "\n",
    "                grid = torch.cat(outs, dim=0)\n",
    "                save_image(grid * 0.5 + 0.5,\n",
    "                          f\"{CFG['out_dir']}/samples/{it:06d}.jpg\",\n",
    "                          nrow=current_ref.size(0), padding=4, pad_value=1)\n",
    "               \n",
    "                ref_names = [domain_names[d] for d in ref_domains.cpu()]\n",
    "                print(f\"\\nğŸ­ Sample {it}: {ref_names} â†’ [JEUNE, ADULTE, Ã‚GÃ‰]\")\n",
    "\n",
    "        G.train(); F_map.train(); F_style.train()\n",
    "\n",
    "    # --- Checkpoint ---\n",
    "    if it % CFG[\"save_every\"] == 0:\n",
    "        torch.save({\n",
    "            \"G\": G.state_dict(),\n",
    "            \"F_map\": F_map.state_dict(),\n",
    "            \"F_style\": F_style.state_dict(),\n",
    "            \"D\": D.state_dict(),\n",
    "            \"opt_g\": opt_g.state_dict(),\n",
    "            \"opt_d\": opt_d.state_dict(),\n",
    "            \"iter\": it\n",
    "        }, f\"{CFG['out_dir']}/checkpoints/checkpoint_{it}.pth\")\n",
    "\n",
    "    pbar.set_postfix({\n",
    "        \"D\": f\"{loss_d.item():.4f}\",\n",
    "        \"G\": f\"{loss_g.item():.4f}\",\n",
    "        \"Cyc\": f\"{loss_cyc.item():.4f}\",\n",
    "        \"Sty\": f\"{loss_sty.item():.4f}\"\n",
    "    })\n",
    "    pbar.update(1)\n",
    "\n",
    "print(\"ğŸ‰ Training terminÃ© ! ModÃ¨le final sauvegardÃ©.\")\n",
    "torch.save({\n",
    "    \"G\": G.state_dict(),\n",
    "    \"F_map\": F_map.state_dict(),\n",
    "    \"F_style\": F_style.state_dict(),\n",
    "    \"D\": D.state_dict(),\n",
    "    \"CFG\": CFG\n",
    "}, f\"{CFG['out_dir']}/final_model_30k.pth\")\n",
    "\n",
    "# ====================== TEST FINAL ======================\n",
    "print(\"\\nğŸ§ª Test final des transformations...\")\n",
    "G.eval(); F_map.eval()\n",
    "with torch.no_grad():\n",
    "    test_img = real[0:1] # PremiÃ¨re image du batch\n",
    "    source_domain = real_domain[0].item()\n",
    "   \n",
    "    print(f\"Image source: {domain_names[source_domain]}\")\n",
    "   \n",
    "    for target_domain in range(CFG[\"n_domains\"]):\n",
    "        if target_domain != source_domain:\n",
    "            z = torch.randn(1, CFG[\"latent_dim\"], device=device)\n",
    "            style = F_map(z, torch.tensor([target_domain], device=device))\n",
    "            result = G(test_img, style)\n",
    "           \n",
    "            save_image(result * 0.5 + 0.5,\n",
    "                      f\"{CFG['out_dir']}/test_{domain_names[source_domain]}_to_{domain_names[target_domain]}.jpg\")\n",
    "            print(f\" â†’ {domain_names[target_domain]} : sauvegardÃ©\")\n",
    "\n",
    "print(\"âœ… Tous les tests sont terminÃ©s !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "861cae8e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-28T19:37:57.234828Z",
     "iopub.status.busy": "2025-11-28T19:37:57.234209Z",
     "iopub.status.idle": "2025-11-28T19:37:57.566345Z",
     "shell.execute_reply": "2025-11-28T19:37:57.565493Z",
     "shell.execute_reply.started": "2025-11-28T19:37:57.234780Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from IPython.display import FileLink\n",
    "\n",
    "# Juste le modÃ¨le final + config\n",
    "!cp /kaggle/working/starganv2_optimized/final_model_30k.pth ./final_model_30k.pth\n",
    "FileLink(r'final_model_30k.pth')\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 6552979,
     "sourceId": 10610809,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31193,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 42.139842,
   "end_time": "2025-11-28T19:43:53.869530",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-11-28T19:43:11.729688",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
